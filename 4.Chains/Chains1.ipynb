{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Expression Language Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  LangChain Expression Language is that any two runnables can be \"chained\" together into sequences. \n",
    "- The output of the previous runnable's .invoke() call is passed as input to the next runnable.\n",
    "- This can be done using the pipe operator (|), or the more explicit .pipe() method, which does the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Type of LCEL Chains\n",
    "    - SequentialChain\n",
    "    - Parallel Chain\n",
    "    - Router Chain\n",
    "    - Chain Runnables\n",
    "    - Custom Chain (Runnable Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate\n",
    "                                        )\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamil_teacher_prompt = \"\"\"Your name is Dhanush, a Tamil teacher. \n",
    "                        Explain the following Tamil language concept to a beginner:\n",
    "                        Question : {question}\n",
    "                        Answer :\n",
    "                        \"\"\"\n",
    "\n",
    "tamil_teacher_template = ChatPromptTemplate.from_template(tamil_teacher_prompt)\n",
    "tamil_teacher_chain = llm | tamil_teacher_template | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define teacher prompt templates and \n",
    "math_teacher_prompt = \"\"\"Your name is Robert, a Math teacher. \n",
    "                        Explain the following math concept to a 7th-grade student\n",
    "                        Question:{question}\n",
    "                        Answer: \n",
    "                        \"\"\"\n",
    "\n",
    "math_teacher_template = ChatPromptTemplate.from_template(math_teacher_prompt)\n",
    "math_teacher_chain =  llm | math_teacher_template | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the history teacher prompt template\n",
    "history_teacher_prompt = \"\"\"Your name is Vignesh, a History teacher. \n",
    "                            Explain the following history concept to a high school student\n",
    "                            question : {question}\n",
    "                            Answer :\n",
    "                          \"\"\"\n",
    "# Create the ChatPromptTemplate\n",
    "history_teacher_template = ChatPromptTemplate.from_template(history_teacher_prompt)\n",
    "# Create the history teacher chain\n",
    "history_teacher_chain = llm | history_teacher_template | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the input question\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Invoke the chain with the correct variable name\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmath_teacher_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwrite a 20 table till 20?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:287\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m--> 287\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:273\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m     )\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "# Define the input question\n",
    "\n",
    "# Invoke the chain with the correct variable name\n",
    "response = math_teacher_chain.invoke({'question':'write a 20 table till 20?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=429fa5f4-687f-4c4c-85c7-c31eef1c7f13,id=429fa5f4-687f-4c4c-85c7-c31eef1c7f13; trace=ede0d332-34f3-4273-b8f0-8d8f99833ff2,id=ede0d332-34f3-4273-b8f0-8d8f99833ff2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an overview of the solar system:\n",
      "\n",
      "1. The sun is at the center, making up 99.8% of the mass.\n",
      "2. There are eight planets: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\n",
      "3. The four gas giants (Jupiter, Saturn) have no solid surface; they're mostly air and water vapor.\n",
      "4. Pluto was previously considered a planet but is now classified as a dwarf planet.\n",
      "5. Asteroids and comets are also part of the solar system, although their orbits may not be directly under our sun's influence.\n"
     ]
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "question = template.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "\n",
    "response = llm.invoke(question)\n",
    "print(response.content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "chain = template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04,id=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04; trace=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04,id=d6720812-522a-48bc-8680-eb9c0f37a514; trace=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04,id=be4d2ed6-d7e1-4086-8648-e640bc995b9d; trace=ede0d332-34f3-4273-b8f0-8d8f99833ff2,id=ede0d332-34f3-4273-b8f0-8d8f99833ff2\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198,id=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198; trace=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198,id=2055c3a1-ddab-4385-9e6e-ba382757616d; trace=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198,id=986cbccf-8e65-4313-8776-a4d76fc085f4; trace=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04,id=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04; trace=3c62be47-4ff1-4bb1-8efd-6d6f204a9a04,id=be4d2ed6-d7e1-4086-8648-e640bc995b9d\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=13c5a58d-e043-44fe-9652-b4f60f15fa21; trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=3bcf953a-3875-4c62-a860-9f75dc944cd3; trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=f3f74587-5191-4929-92f4-b44533d43959; trace=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198,id=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198; trace=c1ba1ec2-a02f-4210-b6c5-1f4efdd4d198,id=986cbccf-8e65-4313-8776-a4d76fc085f4\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=366ab6f0-4515-467b-968e-b04bc53a40e7; trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=13c5a58d-e043-44fe-9652-b4f60f15fa21; trace=13c5a58d-e043-44fe-9652-b4f60f15fa21,id=f3f74587-5191-4929-92f4-b44533d43959\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=d42cd363-75e8-4f69-8fab-492d4390be19,id=d42cd363-75e8-4f69-8fab-492d4390be19; trace=d42cd363-75e8-4f69-8fab-492d4390be19,id=2ecb2999-738d-4677-aed0-9ab8fda7eb7b; trace=d42cd363-75e8-4f69-8fab-492d4390be19,id=6c9d0965-15b7-4313-9423-dc0bc4dffc7c; trace=d42cd363-75e8-4f69-8fab-492d4390be19,id=b286e2ce-dfd3-4f70-8370-224fe12e1d99; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=558a9d81-59f0-4c29-be78-231aeb936fea; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=aed58278-f80e-4c73-8a43-990836276d84; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=0a528568-53f0-4a5a-b75b-378836396800; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=1ea5a41e-5b4d-4d7d-8f5c-7875df017a2c; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=ac076685-76e7-4215-95eb-5e73cb2bfbe9; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=0e62e27e-a5e6-4ccb-97cb-3c9eb5ce1e74; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=90e1ad72-2975-4034-aedb-d8d58d29708a; trace=20179a6d-12b5-409b-a7c8-3e7cb7fe40b4,id=08706d13-0f22-4497-b532-b8893e2efeaa; trace=fdaabe8a-e1d6-4ad1-9bd4-b297f87e5180,id=fdaabe8a-e1d6-4ad1-9bd4-b297f87e5180; trace=fdaabe8a-e1d6-4ad1-9bd4-b297f87e5180,id=2fa77fe3-842a-4969-a897-7d6c9acdc190; trace=fdaabe8a-e1d6-4ad1-9bd4-b297f87e5180,id=9ac9f496-03aa-4e04-8e02-f7620777ef04; trace=fdaabe8a-e1d6-4ad1-9bd4-b297f87e5180,id=95898c95-474d-4323-9369-b4ac6219a692; trace=825c5567-8dd3-4b53-b083-b71183ee0c1c,id=825c5567-8dd3-4b53-b083-b71183ee0c1c; trace=825c5567-8dd3-4b53-b083-b71183ee0c1c,id=718a0798-7c1a-4ae9-8dd1-79f9d7aa60c6; trace=825c5567-8dd3-4b53-b083-b71183ee0c1c,id=0a960b96-38eb-4e96-8103-c6267aa075a6; trace=825c5567-8dd3-4b53-b083-b71183ee0c1c,id=4ffd5468-b380-4b55-b283-30595f87bfc4; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=2f059fee-bb2e-45a7-82b4-b1315c1a6a5a; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=bd1851a0-4478-4d18-8b0f-b7d39e34bcf2; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=6dbfc123-9bb7-4b48-8071-a0173d50cf06; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=4ed5e831-1aa5-4b05-8f1e-a71e6c3b15e1; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=41d40cef-0bdc-40d2-a9d9-acd15bfa4fb9; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=a3739046-9d28-4c1b-941a-6ab696c85e22; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=c15c9512-4923-4b08-a800-9a4432a37868; trace=78a0cb49-cafe-4f0e-b8a8-3bc87de370d5,id=c81a6656-90b2-41d2-8f6f-a76566aa52f3; trace=0a3d9595-30d7-406f-a21a-e09e3f855d4d,id=0a3d9595-30d7-406f-a21a-e09e3f855d4d; trace=0a3d9595-30d7-406f-a21a-e09e3f855d4d,id=33008df8-96ee-4332-a1d1-30154d440e2a; trace=0a3d9595-30d7-406f-a21a-e09e3f855d4d,id=3669778a-3e20-4bb3-99a3-daacd5326db9; trace=0a3d9595-30d7-406f-a21a-e09e3f855d4d,id=cbfdd44e-95ea-46b3-b9c6-b5fe93268775; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=ec951d8a-d745-4717-a068-64d06f95f5ae; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=67dfddb1-121f-4a58-ab68-d65d69eb3bd0; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=1fb98f0f-111a-49d1-8620-a0f673c43b42; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=765f2c9f-58e5-48d1-9e8b-f8230ff53197; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=d66bfff3-b5b2-4dfa-8299-cd8f0390d31d; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=0bae62a8-42b6-4ade-bd15-9fa57da8a51b; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=bfeaa002-2238-4562-9b8d-def7e6bbcb4d; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=49026153-de91-4f49-b49d-d662c59cbcb9; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=7c71ebb4-fc01-4a11-bc08-9fcef6d249fa; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=4f7fd067-f453-4147-bb25-032a29832927; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=f712d0c0-79e0-4d7a-8387-09c8e84f6038\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=3c8482c0-140d-453d-8142-2156598387d4; trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=5228a135-12cb-4462-8ebf-4853e207d0fb; trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=2fb7ac7b-4a2f-4f2f-9428-f9c1fecab89c; trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=376fb44c-542f-4723-bfbf-adfbc18093c3; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=ec951d8a-d745-4717-a068-64d06f95f5ae; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=49026153-de91-4f49-b49d-d662c59cbcb9; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=7c71ebb4-fc01-4a11-bc08-9fcef6d249fa; trace=ec951d8a-d745-4717-a068-64d06f95f5ae,id=4f7fd067-f453-4147-bb25-032a29832927\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=c127714e-4e13-43f7-9f73-85fc0210ca24; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=43b83df8-3a2f-48c3-b65d-847db49179d5; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=817b3ed9-6e61-4476-9e9e-67b71f71c149; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=a351abb2-f144-4779-937d-46aaa9e63319; trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=5228a135-12cb-4462-8ebf-4853e207d0fb; trace=5228a135-12cb-4462-8ebf-4853e207d0fb,id=376fb44c-542f-4723-bfbf-adfbc18093c3\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=42969d6a-54dd-4651-bbdf-c492936fd9e4; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=b02736bc-80d7-4c7f-b6bc-d63d68c65e7a; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=550f2f57-5359-467a-9158-8976fbdac29d; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=8fe681f7-538f-41ad-9990-822552bcd5a0; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=ba85d010-2911-47b1-bd90-29a179391597; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=25e2d5cd-94e0-4fae-988a-fb0cbc40a125; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=eaa6c11c-f836-4128-98cb-5a537c6d6e61; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=237fb884-080e-4027-8537-6875fa0a1faf; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=b1a348ab-fe02-4153-9ddc-d6934f55b312; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=a351abb2-f144-4779-937d-46aaa9e63319; trace=43b83df8-3a2f-48c3-b65d-847db49179d5,id=43b83df8-3a2f-48c3-b65d-847db49179d5\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=70c0eb24-f466-4aa5-92cf-d33d66b90baf; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=cec174b6-b73b-4eff-a3cf-8c847649c315; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=76aaa89f-543d-4c04-a6b4-b5fb21007338; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=da03ca66-d578-42b5-86ad-c3dd3bd0672b; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=eaa6c11c-f836-4128-98cb-5a537c6d6e61; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=237fb884-080e-4027-8537-6875fa0a1faf\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=d15d3e35-7259-4a5c-994f-ae09d802bc7a; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=25e2d5cd-94e0-4fae-988a-fb0cbc40a125; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=cec174b6-b73b-4eff-a3cf-8c847649c315; trace=25e2d5cd-94e0-4fae-988a-fb0cbc40a125,id=da03ca66-d578-42b5-86ad-c3dd3bd0672b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what you need to know about our solar system:\n",
      "\n",
      "1. There are eight planets in it, and they're listed in order from the Sun: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\n",
      "\n",
      "2. The four largest planets are called gas giants, because of their huge size and mostly made up of gases like hydrogen and helium.\n",
      "\n",
      "3. The planets get smaller and smaller as you go further out from the Sun, until they reach Mercury.\n",
      "\n",
      "4. There's a big planet that's really far away from the Sun - it's named Neptune.\n",
      "\n",
      "5. Jupiter is a special planet because it has lots of moons and is really huge compared to other planets in our solar system.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an overview of the solar system:\n",
      "\n",
      "â€¢ **The Sun**: At its center is our star, a massive ball of hot, glowing gas that provides light and heat to our planets.\n",
      "\n",
      "â€¢ **Mercury, Venus, Earth, Mars**: These rocky planets are closest to the Sun and have no atmospheres. They're rocky, barren worlds with extreme temperatures and few liquid water sources.\n",
      "\n",
      "â€¢ **Jupiter, Saturn, Uranus, Neptune**: These gas giants are massive balls of hydrogen and helium. Jupiter is the largest planet, while Saturn has a ring system that's made up of ice and rock particles.\n",
      "\n",
      "â€¢ **Makemake, Haumea, Eris**: These icy bodies are dwarf planets, with surfaces composed primarily of water ice and darker organic material. They're found in the outer reaches of our solar system.\n",
      "\n",
      "â€¢ **The Kuiper Belt and Oort Cloud**: These regions contain many small, icy objects that orbit the Sun beyond Neptune's orbit. The Kuiper Belt is a disk-shaped zone of icy bodies, while the Oort Cloud is a distant, spherical shell of icy objects that surrounds the Solar System.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's an overview of the solar system:\\n\\nâ€¢ **The Sun**: At its center is our star, a massive ball of hot, glowing gas that provides light and heat to our planets.\\n\\nâ€¢ **Mercury, Venus, Earth, Mars**: These rocky planets are closest to the Sun and have no atmospheres. They're rocky, barren worlds with extreme temperatures and few liquid water sources.\\n\\nâ€¢ **Jupiter, Saturn, Uranus, Neptune**: These gas giants are massive balls of hydrogen and helium. Jupiter is the largest planet, while Saturn has a ring system that's made up of ice and rock particles.\\n\\nâ€¢ **Makemake, Haumea, Eris**: These icy bodies are dwarf planets, with surfaces composed primarily of water ice and darker organic material. They're found in the outer reaches of our solar system.\\n\\nâ€¢ **The Kuiper Belt and Oort Cloud**: These regions contain many small, icy objects that orbit the Sun beyond Neptune's orbit. The Kuiper Belt is a disk-shaped zone of icy bodies, while the Oort Cloud is a distant, spherical shell of icy objects that surrounds the Solar System.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2024-12-18T14:21:40.7315633Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5318262300, 'load_duration': 34084900, 'prompt_eval_count': 47, 'prompt_eval_duration': 10000000, 'eval_count': 230, 'eval_duration': 5268000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-986cbccf-8e65-4313-8776-a4d76fc085f4-0', usage_metadata={'input_tokens': 47, 'output_tokens': 230, 'total_tokens': 277})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what you need to know about the solar system:\n",
      "\n",
      "1. The solar system is made up of eight planets: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\n",
      "\n",
      "2. There are five other objects that orbit around our sun: dwarf planets like Pluto and Eris, asteroids, comets, and moons (like Io, Europa, and Ganymede).\n",
      "\n",
      "3. The four largest planets in our solar system are known as the \"Gas Giants\": Jupiter, Saturn, Uranus, and Neptune.\n",
      "\n",
      "4. Mercury is the closest planet to the sun, while Neptune is the farthest.\n",
      "\n",
      "5. Venus has a thick atmosphere that traps heat, making it the hottest planet in the solar system.\n"
     ]
    }
   ],
   "source": [
    "chain = template | llm | StrOutputParser()\n",
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s what you need to know about the solar system:\\n\\n1. The solar system is made up of eight planets: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\\n\\n2. There are five other objects that orbit around our sun: dwarf planets like Pluto and Eris, asteroids, comets, and moons (like Io, Europa, and Ganymede).\\n\\n3. The four largest planets in our solar system are known as the \"Gas Giants\": Jupiter, Saturn, Uranus, and Neptune.\\n\\n4. Mercury is the closest planet to the sun, while Neptune is the farthest.\\n\\n5. Venus has a thick atmosphere that traps heat, making it the hottest planet in the solar system.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Runnables (Chain Multiple Runnables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can even combine this chain with more runnables to create another chain.\n",
    "- Let's see how easy our generated output is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['points', 'school', 'topics'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['school'], input_types={}, partial_variables={}, template='You are {school} teacher. You answer in short sentences.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['points', 'topics'], input_types={}, partial_variables={}, template='tell me about the {topics} in {points} points'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text appears to be written at a 7th or 8th grade level of reading proficiency, requiring some basic knowledge of astronomy and planetary names but may lack complex vocabulary and nuanced explanations for advanced readers.\n"
     ]
    }
   ],
   "source": [
    "analysis_prompt = ChatPromptTemplate.from_template('''analyze the following text: {response}\n",
    "                                                   You need tell me that how difficult it is to understand.\n",
    "                                                   Answer in one sentence only.\n",
    "                                                   ''')\n",
    "\n",
    "fact_check_chain = analysis_prompt | llm | StrOutputParser()\n",
    "output = fact_check_chain.invoke({'response': response})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is written in a clear and concise manner, using simple language to explain complex concepts related to the solar system, making it accessible to readers with varying levels of knowledge or experience.\n"
     ]
    }
   ],
   "source": [
    "composed_chain = {\"response\": chain} | analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "output = composed_chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 5})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel LCEL Chain\n",
    "- Parallel chains are used to run multiple runnables in parallel.\n",
    "- The final return value is a dict with the results of each value under its appropriate key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an overview of the solar system:\n",
      "\n",
      "* The Sun is at the center, providing light and heat to all planets.\n",
      "* The inner planets (Mercury, Venus, Earth, and Mars) orbit very close to the Sun.\n"
     ]
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "fact_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = fact_chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun is the center of our place,\n",
      "Eight planets orbit around its steady pace.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessagePromptTemplate.from_template('write a poem on {topics} in {sentences} lines')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "poem_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = poem_chain.invoke({'school': 'primary', 'topics': 'solar system', 'sentences': 2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(fact = fact_chain, poem = poem_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what you need to know:\n",
      "\n",
      "* The sun is at the center of our solar system and makes up 99% of its mass.\n",
      "* There are eight planets (Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, Jupiter) that orbit around the sun in different paths.\n",
      "\n",
      "\n",
      "\n",
      "The sun is at the center, \n",
      "Planets spin around, in their own way.\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 2, 'sentences': 2})\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Router\n",
    "- The router chain is used to route the output of a previous runnable to the next runnable based on the output of the previous runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Given the user review below, classify it as either being about `Positive` or `Negative`.\n",
    "            Do not respond with more than one word.\n",
    "\n",
    "            Review: {review}\n",
    "            Classification:\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "review = \"Thank you so much for providing such a great plateform for learning. I am really happy with the service.\"\n",
    "# review = \"I am not happy with the service. It is not good.\"\n",
    "chain.invoke({'review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"\n",
    "                You are expert in writing reply for positive reviews.\n",
    "                You need to encourage the user to share their experience on social media.\n",
    "                Review: {review}\n",
    "                Answer:\"\"\"\n",
    "\n",
    "positive_template = ChatPromptTemplate.from_template(positive_prompt)\n",
    "positive_chain = positive_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"\"\"\n",
    "                You are expert in writing reply for negative reviews.\n",
    "                You need first to apologize for the inconvenience caused to the user.\n",
    "                You need to encourage the user to share their concern on following Email:'udemy@kgptalkie.com'.\n",
    "                Review: {review}\n",
    "                Answer:\"\"\"\n",
    "\n",
    "\n",
    "negative_template = ChatPromptTemplate.from_template(negative_prompt)\n",
    "negative_chain = negative_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rout(info):\n",
    "    if 'positive' in info['sentiment'].lower():\n",
    "        return positive_chain\n",
    "    else:\n",
    "        return negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rout({'sentiment': 'negetive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\"sentiment\": chain, 'review': lambda x: x['review']} | RunnableLambda(rout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  sentiment: ChatPromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, template='Given the user review below, classify it as either being about `Positive` or `Negative`.\\n            Do not respond with more than one word.\\n\\n            Review: {review}\\n            Classification:'), additional_kwargs={})])\n",
       "             | ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')\n",
       "             | StrOutputParser(),\n",
       "  review: RunnableLambda(lambda x: x['review'])\n",
       "}\n",
       "| RunnableLambda(rout)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so sorry to hear that your experience with our service hasn't met your expectations. We apologize for any inconvenience or disappointment caused and appreciate you bringing this to our attention.\n",
      "\n",
      "We understand that our service didn't meet your requirements, and we're truly sorry that it didn't deliver on the promises we made. Your satisfaction is of utmost importance to us, and we're committed to making things right.\n",
      "\n",
      "We'd like to assure you that we're taking immediate action to address the issues that have arisen. We'll be looking into this matter closely and taking necessary steps to prevent similar incidents in the future.\n",
      "\n",
      "In light of your experience, we'd like to reach out to you personally to hear your concerns and gather more information about what went wrong. Your feedback is invaluable to us, and we're committed to using it to improve our services.\n",
      "\n",
      "If you're willing, please could you share your concern with us via email at udemy@kgptalkie.com? We'd love to hear from you and would like to know how we can better serve you in the future. Your input will help us to identify areas for improvement and provide a more exceptional experience for our students.\n",
      "\n",
      "Once again, we apologize for any inconvenience caused and appreciate your feedback. We value your business and look forward to the opportunity to serve you better in the future.\n"
     ]
    }
   ],
   "source": [
    "# review = \"Thank you so much for providing such a great plateform for learning. I am really happy with the service.\"\n",
    "review = \"I am not happy with the service. It is not good.\"\n",
    "\n",
    "output = full_chain.invoke({'review': review})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Custom Chain Runnables with RunnablePassthrough and RunnableLambda\n",
    "- This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called RunnableLambdas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_counts(text):\n",
    "    return len(text)\n",
    "\n",
    "def word_counts(text):\n",
    "    return len(text.split())\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Explain these inputs in 5 sentences: {input1} and {input2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input1', 'input2'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input1', 'input2'], input_types={}, partial_variables={}, template='Explain these inputs in 5 sentences: {input1} and {input2}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five sentences explaining the difference between an Earth and a Sun:\n",
      "\n",
      "The Earth is actually a planet, not a star. In fact, it's a special type of planet called a terrestrial planet that orbits around a larger body called the Sun. While the Sun is a massive ball of hot, glowing gas, it doesn't have a solid surface like the Earth does. The Earth and Sun are two separate celestial bodies that exist in our solar system, with different roles to play in supporting life on our planet. Understanding these differences helps us appreciate the unique characteristics and functions of each object in our universe.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({'input1': 'Earth is planet', 'input2': 'Sun is star'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_counts': 648, 'word_counts': 120, 'output': 'The statement \"Earth is a planet and the Sun is a star\" refers to the fundamental characteristics of our solar system. In astronomy, a planet is a celestial body that orbits around a star, and Earth fits this definition as it orbits the Sun. The Sun, on the other hand, is a massive ball of hot, glowing gas that is at the center of our solar system. The term \"star\" can also refer to any large, luminous ball of gas in space that is held together by its own gravity, including the Sun and other planets like Earth. By identifying the characteristics of a planet and a star, we can understand the basic structure and components of our solar system.'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser() | {'char_counts': RunnableLambda(char_counts), \n",
    "                                            'word_counts': RunnableLambda(word_counts), \n",
    "                                            'output': RunnablePassthrough()}\n",
    "\n",
    "output = chain.invoke({'input1': 'Earth is planet', 'input2': 'Sun is star'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Chain using `@chain` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two key points about the solar system:\n",
      "\n",
      "*   The sun is at the center of our solar system and is responsible for its warmth and light.\n",
      "*   The planets, including Earth, Mars, and Jupiter, orbit around the sun due to their own gravity.\n",
      "\n",
      "\n",
      "\n",
      "The sun at center, planets spin round,\n",
      "Mars, Jupiter and Earth, our planet found.\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def custom_chain(params):\n",
    "    return {\n",
    "        'fact': fact_chain.invoke(params),\n",
    "        'poem': poem_chain.invoke(params),\n",
    "    }\n",
    "\n",
    "\n",
    "params = {'school': 'primary', 'topics': 'solar system', 'points': 2, 'sentences': 2}\n",
    "output = custom_chain.invoke(params)\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
