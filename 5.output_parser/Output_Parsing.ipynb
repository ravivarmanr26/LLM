{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Output Parsers in LangChain**\n",
    "\n",
    "LangChain provides a variety of **output parsers** to transform the raw output of language models into structured formats. These parsers are useful for generating structured data, normalizing chat model outputs, or handling specific formats like JSON, XML, CSV, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "1. **Purpose of Output Parsers**:\n",
    "   - Convert raw text output from models into structured formats (e.g., JSON, XML, CSV).\n",
    "   - Normalize outputs for downstream tasks.\n",
    "   - Useful for generating structured data or handling specific formats.\n",
    "\n",
    "2. **Function/Tool Calling**:\n",
    "   - Modern models support **function/tool calling**, which automatically handles structured outputs.\n",
    "   - Recommended over manual output parsing for better integration and efficiency.\n",
    "\n",
    "3. **Types of Output Parsers**:\n",
    "   - **Str**: Parses text from message objects.\n",
    "   - **JSON**: Returns a JSON object based on a Pydantic model.\n",
    "   - **XML**: Converts XML output into a dictionary.\n",
    "   - **CSV**: Parses comma-separated values into a list.\n",
    "   - **OutputFixing**: Fixes errors in output by passing them to an LLM.\n",
    "   - **RetryWithError**: Similar to `OutputFixing`, but also sends original instructions.\n",
    "   - **Pydantic**: Parses output into a user-defined Pydantic model.\n",
    "   - **YAML**: Parses output into a Pydantic model using YAML encoding.\n",
    "   - **PandasDataFrame**: Converts output into a pandas DataFrame.\n",
    "   - **Enum**: Parses output into one of the provided enum values.\n",
    "   - **Datetime**: Parses output into a datetime object.\n",
    "   - **Structured**: Returns structured information as a dictionary of strings.\n",
    "\n",
    "4. **Features of Output Parsers**:\n",
    "   - **Supports Streaming**: Some parsers support streaming outputs.\n",
    "   - **Has Format Instructions**: Most parsers provide format instructions for the model.\n",
    "   - **Calls LLM**: Some parsers (e.g., `OutputFixing`) call an LLM to correct errors.\n",
    "   - **Input Type**: Most parsers accept strings or messages, but some require specific formats (e.g., OpenAI function calling).\n",
    "   - **Output Type**: The parser's output type varies (e.g., JSON object, dictionary, Pydantic model).\n",
    "\n",
    "5. **Recommendation**:\n",
    "   - Use **function/tool calling** for automatic structured output handling when available.\n",
    "   - Use output parsers for custom or legacy workflows that require structured data.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use Output Parsers**\n",
    "\n",
    "- When generating structured data (e.g., JSON, XML, CSV).\n",
    "- When normalizing chat model outputs.\n",
    "- When working with smaller LLMs that don’t support function/tool calling.\n",
    "\n",
    "---\n",
    "\n",
    "### **Note**\n",
    "\n",
    "- **Function/Tool Calling** is the recommended approach for structured outputs in modern models.\n",
    "- LangChain’s output parsers are powerful tools for custom workflows, especially when working with legacy models or specific formats.\n",
    "- Choose the appropriate parser based on the desired output format and model capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models output text. But there are times where you want to get more structured information than just text back\n",
    "\n",
    "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "- **Get format instructions**: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- **Parse**: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output Parsing\n",
    "    - StrOutputParser\n",
    "    - JsonOutputParser\n",
    "    - CSV Output Parser\n",
    "    - Datatime Output Parser\n",
    "    - Structured Output Parser (Pydanitc or Json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                    SystemMessagePromptTemplate,\n",
    "                                    HumanMessagePromptTemplate,\n",
    "                                    ChatMessagePromptTemplate,\n",
    "                                    PromptTemplate\n",
    ")\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2'\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model=model,\n",
    "    temperature=0.7\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='It\\'s great that you\\'re supporting your friend Vignesh and his partner Robert. Having a supportive network of friends and family can make a big difference in the lives of LGBTQ+ individuals.\\n\\nIf you\\'d like to include their names on social media or in any other context, here are some tips:\\n\\n1. Use their preferred names: Make sure to use Vignesh and Robert\\'s preferred names when referring to them. This shows that you respect their identity and want to use the language they prefer.\\n2. Be mindful of pronouns: If you\\'re not sure which pronouns Vignesh and Robert prefer, you can ask them or use neutral pronouns like \"they\" or \"them.\"\\n3. Avoid assumptions: Don\\'t assume someone\\'s sexual orientation based on their appearance, behavior, or other characteristics. Ask people about their preferences if you\\'re unsure.\\n4. Be an ally: As a supportive friend, you can help create a welcoming environment for Vignesh and Robert. Listen to their experiences, offer support, and advocate for their rights when needed.\\n\\nRemember that every individual\\'s journey is unique, and it\\'s essential to respect people\\'s boundaries and preferences. By being a good friend and ally, you can help make a positive impact in Vignesh and Robert\\'s lives.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-24T06:07:13.9724192Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14388336100, 'load_duration': 4758599300, 'prompt_eval_count': 41, 'prompt_eval_duration': 606000000, 'eval_count': 260, 'eval_duration': 9012000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-b3e3b64c-9d8c-467f-a640-9c3993a468ba-0' usage_metadata={'input_tokens': 41, 'output_tokens': 260, 'total_tokens': 301}\n"
     ]
    }
   ],
   "source": [
    "input_question = \"my friend name is vignesh, he is gay, his partner name is robert\"\n",
    "res = llm.invoke(input_question)  \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pydantinc` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic is a Python library that leverages type annotations to enforce data validation and manage settings, ensuring data consistency and integrity. It's particularly beneficial in web development and API design, where strict data validation is crucial.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "1. **What is Pydantic?**\n",
    "   - Pydantic allows developers to define data models using Python classes with type annotations. It validates input data against these annotations, ensuring that the data adheres to the expected types and constraints. \n",
    "\n",
    "2. **How Does Pydantic Work?**\n",
    "   - **Define a Pydantic Model**: Create a class that inherits from `BaseModel`, specifying attributes with type hints.\n",
    "   - **Instantiate the Model**: When you create an instance of this model, Pydantic validates the input data against the defined types.\n",
    "   - **Access and Manipulate Data**: After validation, you can access and manipulate the data through the model's attributes, confident that it meets the specified criteria.\n",
    "\n",
    "3. **Why Use Pydantic?**\n",
    "   - **Validation**: Automatically ensures that data conforms to the specified types, reducing runtime errors.\n",
    "   - **Parsing**: Converts input data into the appropriate types, facilitating seamless data handling.\n",
    "   - **Integration**: Works seamlessly with frameworks like FastAPI, enhancing rapid development of robust APIs. \n",
    "\n",
    "**Example Program:**\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, EmailStr\n",
    "\n",
    "# Define a Pydantic model\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: EmailStr\n",
    "\n",
    "# Instantiate the model with valid data\n",
    "user = User(name=\"Alice\", age=30, email=\"alice@example.com\")\n",
    "\n",
    "# Access and manipulate data\n",
    "print(user.name)   # Output: Alice\n",
    "print(user.age)    # Output: 30\n",
    "print(user.email)  # Output: alice@example.com\n",
    "\n",
    "# Attempt to instantiate with invalid data\n",
    "try:\n",
    "    invalid_user = User(name=\"Bob\", age=\"thirty\", email=\"bob[at]example.com\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # Output: 2 validation errors for User\n",
    "    # age\n",
    "    #   value is not a valid integer (type=type_error.integer)\n",
    "    # email\n",
    "    #   value is not a valid email address (type=value_error.email)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Defining the Model**: The `User` class inherits from `BaseModel` and specifies three attributes: `name` (a string), `age` (an integer), and `email` (a string that must be a valid email address, enforced by `EmailStr`).\n",
    "\n",
    "- **Instantiating with Valid Data**: Creating an instance of `User` with valid data (`name=\"Alice\"`, `age=30`, `email=\"alice@example.com\"`) succeeds, and you can access the attributes directly.\n",
    "\n",
    "- **Instantiating with Invalid Data**: Attempting to create a `User` instance with invalid data (`age=\"thirty\"` and `email=\"bob[at]example.com\"`) raises validation errors. Pydantic provides detailed error messages indicating that `age` is not a valid integer and `email` is not a valid email address.\n",
    "\n",
    "This example demonstrates how Pydantic enforces data validation, ensuring that only data conforming to the specified types and formats is accepted, thereby enhancing data integrity and application robustness.\n",
    "\n",
    "For a more in-depth understanding, you might find the following video helpful:\n",
    "\n",
    "[Pydantic: Data Validation and Settings Management Using Python Type Annotations](https://www.youtube.com/watch?v=R0RwdOc338w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username='johndoe' email='johndoe@example.com' age=30 signup_date=datetime.date(2023, 1, 15)\n",
      "3 validation errors for User\n",
      "email\n",
      "  value is not a valid email address: An email address must have an @-sign. [type=value_error, input_value='not-an-email', input_type=str]\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='twenty-five', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\n",
      "signup_date\n",
      "  Input should be a valid date or datetime, invalid character in year [type=date_from_datetime_parsing, input_value='15th January 2023', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/date_from_datetime_parsing\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, EmailStr, ValidationError\n",
    "from typing import Optional\n",
    "from datetime import date\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    email: EmailStr\n",
    "    age: Optional[int]\n",
    "    signup_date: date\n",
    "\n",
    "# Valid data\n",
    "try:\n",
    "    user = User(\n",
    "        username='johndoe',\n",
    "        email='johndoe@example.com',\n",
    "        age=30,\n",
    "        signup_date='2023-01-15'\n",
    "    )\n",
    "    print(user)\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "# Invalid data\n",
    "try:\n",
    "    user = User(\n",
    "        username='janedoe',\n",
    "        email='not-an-email',\n",
    "        age='twenty-five',\n",
    "        signup_date='15th January 2023'\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pydantinc` Output Parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pydantic Output Parser in LangChain transforms unstructured outputs from Language Learning Models (LLMs) into structured data formats using Pydantic models, ensuring data adheres to predefined schemas for enhanced consistency and reliability.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "What is it? A LangChain component that uses Pydantic models to define the desired structure of LLM outputs, ensuring conformity to specified schemas. \n",
    "LangChain\n",
    "\n",
    "How does it work?\n",
    "\n",
    "Define a Pydantic Model: Create a class inheriting from BaseModel with type-annotated fields representing the desired output structure.\n",
    "Initialize the Parser: Set up the PydanticOutputParser with the defined model.\n",
    "Create a Prompt Template: Design a prompt that includes format instructions from the parser.\n",
    "Generate and Parse Output: Use the LLM to generate a response based on the prompt and parse it into the Pydantic model.\n",
    "Why use it?\n",
    "\n",
    "Structured Data: Ensures LLM outputs adhere to a predefined schema, facilitating easier data handling.\n",
    "Validation: Automatically checks that the output matches the specified types and constraints.\n",
    "Integration: Seamlessly works with other tools and frameworks that utilize Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydantic_object=<class '__main__.Joke'>\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instructions = parser.get_format_instructions()\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"setup\": \"Why did the bus go to the doctor?\", \"punchline\": \"Because it was feeling a little car-sick!\"}' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-24T06:07:17.1655649Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3003974400, 'load_duration': 92927600, 'prompt_eval_count': 251, 'prompt_eval_duration': 1342000000, 'eval_count': 31, 'eval_duration': 1567000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-807a4e29-2f9a-4e85-b04a-1170bf674d91-0' usage_metadata={'input_tokens': 251, 'output_tokens': 31, 'total_tokens': 282}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({'query':'tell me joke about bus'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'}, template='\\n    Answer the user query with a joke. Here is your formatting instruction.\\n    {format_instruction}\\n\\n    Query: {query}\\n    Answer:')\n",
       "| ChatOllama(model='llama3.2', temperature=0.7, base_url='http://localhost:11434')\n",
       "| PydanticOutputParser(pydantic_object=<class '__main__.Joke'>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the bus go to the doctor?' punchline='Because it was feeling a little car-sick!'\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query':'tell me joke about bus'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the moviegoer bring a ladder to the cinema?' punchline=''setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing experience'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing experience to'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing experience to new'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing experience to new heights'setup='Why did the moviegoer bring a ladder to the cinema?' punchline='Because he wanted to take his viewing experience to new heights!'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({\"query\": \"tell me joke about cinema \"}):\n",
    "    print(chunk, end=\"\")  \n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model\n",
    "class Poem(BaseModel):\n",
    "    \"\"\"The Poem Generator\"\"\"\n",
    "    title: str = Field(description=\"The title of the Poem\")\n",
    "    Poem: str = Field(description=\"The actual content of the Poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parser\n",
    "parser = PydanticOutputParser(pydantic_object=Poem)\n",
    "\n",
    "# Get format instructions\n",
    "format_instructions = parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"The Poem Generator\", \"properties\": {\"title\": {\"description\": \"The title of the Poem\", \"title\": \"Title\", \"type\": \"string\"}, \"Poem\": {\"description\": \"The actual content of the Poem\", \"title\": \"Poem\", \"type\": \"string\"}}, \"required\": [\"title\", \"Poem\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instructions = parser.get_format_instructions()\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Write a poem based on the user's query. Here is your formatting instruction:\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM Output: content='{\"title\": \"Feline Delight\", \"Poem\": \"Whiskers soft and eyes so bright, our feline friends shine with delight. With playful pounces and snuggles too, they bring joy to me and you.\"}' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-24T06:07:24.5100307Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3896392600, 'load_duration': 25134900, 'prompt_eval_count': 251, 'prompt_eval_duration': 197000000, 'eval_count': 51, 'eval_duration': 3673000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-ac474641-72d0-4bbd-9d39-1551a5a5dac6-0' usage_metadata={'input_tokens': 251, 'output_tokens': 51, 'total_tokens': 302}\n"
     ]
    }
   ],
   "source": [
    "# Create the chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Debug: Print the raw output of the language model\n",
    "raw_response = chain.invoke({'query': 'write a poem about cats'})\n",
    "print(\"Raw LLM Output:\", raw_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Feline Delight' Poem='Whiskers twitch, ears perk up high\\nMews and purrs, a gentle sigh\\nSoft fur, eyes bright as the night\\nOur feline friends, a pure delight'\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({'query':'write poem about cats'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing with `.with_structured_output()` method\n",
    "- This method takes a schema as input which specifies the names, types, and descriptions of the desired output attributes.\n",
    "-  The schema can be specified as a TypedDict class, JSON Schema or a Pydantic class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a 2-line poem about Tamil:\n",
      "\n",
      "\"Tamil, a language of ancient lore,\n",
      "A testament to the rich heritage we adore.\"\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke('tell me poem about tamil in 2lines')\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableBinding(bound=ChatOllama(model='llama3.2', temperature=0.7, base_url='http://localhost:11434'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Joke', 'description': 'Joke to tell user', 'parameters': {'properties': {'setup': {'description': 'The setup of the joke', 'type': 'string'}, 'punchline': {'description': 'The punchline of the joke', 'type': 'string'}}, 'required': ['setup', 'punchline'], 'type': 'object'}}}]}, config={}, config_factories=[]) middle=[] last=PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Joke'>])\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)\n",
    "print(structured_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "output =  structured_llm.invoke('write Joke about networks')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `JSON` Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': {'setup': 'Why did the scarecrow win an award?',\n",
       "  'punchline': 'Because he was outstanding in his field!'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruction = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"setup\": \"Why did the bus go to the doctor?\", \"punchline\": \"Because it was feeling a little car-sick!\"}' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-24T06:07:35.7147312Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2948307100, 'load_duration': 32453600, 'prompt_eval_count': 251, 'prompt_eval_duration': 269000000, 'eval_count': 31, 'eval_duration': 2645000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-9f74c43e-bc1b-4ced-9ad9-aa9eb125ec9f-0' usage_metadata={'input_tokens': 251, 'output_tokens': 31, 'total_tokens': 282}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'query':'tell me joke about bus'})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'Why did the cat join a band?', 'punchline': 'Because it wanted to be a purr-cussionist!'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({'query':'write a joke  about cat'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Poem(BaseModel):\n",
    "    \"\"\"A Poem with setup and punchline.\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the poem\")\n",
    "    sentence: str = Field(description=\"The sentence of the poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"A Poem with setup and punchline.\", \"properties\": {\"setup\": {\"description\": \"The setup of the poem\", \"title\": \"Setup\", \"type\": \"string\"}, \"sentence\": {\"description\": \"The sentence of the poem\", \"title\": \"Sentence\", \"type\": \"string\"}}, \"required\": [\"setup\", \"sentence\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Poem)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruction = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"properties\": {\"title\": {\"description\": \"The title of the Poem\", \"title\": \"Bus Rides\", \"type\": \"string\"}, \"Poem\": {\"description\": \"The actual content of the Poem\", \"title\": \"Poem\", \"type\": \"string\"}}}\\n\\n\"Title\"\\n\"A bus rumbles down the road\\nIts wheels a-turnin\\', passengers in tow\\nFrom town to town, it makes its way\\nBringing people together every day\"\\n\\n\"Poem\"' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2024-12-24T06:07:43.8772001Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6441311800, 'load_duration': 25812000, 'prompt_eval_count': 248, 'prompt_eval_duration': 206000000, 'eval_count': 104, 'eval_duration': 6203000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d2237df3-72ab-4ee4-aec1-edca336d28e9-0' usage_metadata={'input_tokens': 248, 'output_tokens': 104, 'total_tokens': 352}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer  the user query about poem.Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query : {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction' : format_instructions}\n",
    "    \n",
    ")\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'query':'tell me poem about bus'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'title': {'description': 'The title of the Poem', 'title': 'Title', 'type': 'string'}, 'Poem': {'description': 'The actual content of the Poem', 'title': 'Poem', 'type': 'string'}}, 'required': ['title', 'Poem']}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({'query':'write about cat'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `CSV` Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# value1, values2, values3, so on\n",
    "\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruction = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a list of values. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'Language Models', 'AI', 'Machine Learning', 'Natural Language Processing', 'Deep Learning', 'Artificial Intelligence', 'Text Analysis', 'Sentiment Analysis', 'Language Understanding', 'Conversational AI', 'Chatbots', 'Human-Computer Interaction', 'Information Retrieval', 'Semantic Search']\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'generate my website seo keywords. I have content about the NLP and LLM.'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatime Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gives output in datetime format. Sometimes throws error if the LLM output is not in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1211-09-13T11:13:37.530685Z, 1755-08-06T20:42:04.383087Z, 1613-01-21T06:06:43.226624Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "parser = DatetimeOutputParser()\n",
    "format_instruction =  parser.get_format_instructions()\n",
    "print(format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a datetime. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947-08-15 18:00:00\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "response = chain.invoke({'query':'when india got independence?'})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
